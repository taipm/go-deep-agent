<div align="center">

# Go Deep Agent ðŸš€

[![Go Version](https://img.shields.io/github/go-mod/go-version/taipm/go-deep-agent?style=flat-square&logo=go)](https://golang.org/)
[![Tests](https://img.shields.io/badge/tests-1390%2B%20passing-success?style=flat-square&logo=github)](https://github.com/taipm/go-deep-agent)
[![Coverage](https://img.shields.io/badge/coverage-92%25-success?style=flat-square&logo=codecov)](https://github.com/taipm/go-deep-agent)
[![Version](https://img.shields.io/badge/v0.12.0-blue?style=flat-square)](https://github.com/taipm/go-deep-agent/releases/tag/v0.12.0)
[![Go Report Card](https://goreportcard.com/badge/github.com/taipm/go-deep-agent?style=flat-square)](https://goreportcard.com/report/github.com/taipm/go-deep-agent)
[![License](https://img.shields.io/github/license/taipm/go-deep-agent?style=flat-square)](LICENSE)
[![Stars](https://img.shields.io/github/stars/taipm/go-deep-agent?style=social)](https://github.com/taipm/go-deep-agent/stargazers)

**The #1 Enterprise AI Agent Library for Go**

*[9.5/10 BMAD Method Score â€¢ 99.9% Uptime â€¢ 92% Test Coverage â€¢ MultiProvider System â€¢ Built for Production]*

*ðŸŽ‰ **v0.12.0 Released** - Enterprise MultiProvider system with load balancing, circuit breaker, and BMAD Method implementation*

[Quick Start](#-quick-start) â€¢ [Features](#-features) â€¢ [Examples](examples/) â€¢ [Docs](docs/) â€¢ [Assessment Report](LIBRARY_ASSESSMENT_REPORT.md)

---

</div>

A powerful yet simple LLM agent library for Go with a modern **Fluent Builder API**. Build AI applications with method chaining, automatic conversation memory, intelligent error handling, and seamless streaming support.

Built with [openai-go v3.8.1](https://github.com/openai/openai-go).

> **Why go-deep-agent?** 60-80% less code than openai-go with 10x better developer experience. [See detailed comparison â†’](docs/COMPARISON.md)

## âœ¨ Features

- ðŸŽ¯ **Fluent Builder API** - Natural, readable method chaining
- âš¡ **WithDefaults()** - Production-ready in one line: Memory(20) + Retry(3) + Timeout(30s) + ExponentialBackoff (v0.5.8 ðŸ†•)
- ðŸ¤– **Multi-Provider & Adapters** - OpenAI, Ollama, Gemini + custom adapters with unified API (v0.7.9)
- ðŸ›¡ï¸ **MultiProvider System** - Enterprise-grade load balancing, failover, circuit breaker, health monitoring (v0.11.0 ðŸ†•)
- ðŸ§  **Hierarchical Memory** - 3-tier system (Working â†’ Episodic â†’ Semantic) with automatic importance scoring (v0.6.0 ðŸ†•)
- ï¿½ **Session Persistence** - Save/restore conversations across executions with file-based or custom backends (v0.8.0 ðŸ†•)
- ï¿½ðŸ“¡ **Streaming** - Real-time response streaming with callbacks
- ðŸ› ï¸ **Tool Calling** - Auto-execution with type-safe function definitions
- ðŸ“‹ **Structured Outputs** - JSON Schema with strict mode
- âš¡ **Error Recovery** - Smart retries with exponential backoff
- ðŸŽ›ï¸ **Advanced Controls** - Temperature, top-p, tokens, penalties, seed
- ðŸ§ª **Production Ready** - Timeouts, retries, comprehensive error handling
- ðŸ–¼ï¸ **Multimodal** - Vision support for GPT-4 Vision (images via URL/file/base64)
- ðŸš€ **Batch Processing** - Concurrent request processing with progress tracking (v0.4.0)
- ðŸ“š **RAG Support** - Retrieval-Augmented Generation with document chunking (v0.4.0)
- ðŸ’¾ **Response Caching** - Memory & Redis caching with TTL management (v0.4.0, v0.5.1 ðŸ†•)
- ðŸ”¢ **Vector Embeddings** - OpenAI & Ollama embeddings with similarity search (v0.5.0 ðŸ†•)
- ðŸ—„ï¸ **Vector Databases** - ChromaDB & Qdrant integration for semantic search (v0.5.0 ðŸ†•)
- ðŸ§  **Vector RAG** - Semantic retrieval with auto-embedding and priority system (v0.5.0 ðŸ†•)
- ðŸ“Š **Logging & Observability** - Zero-overhead logging with slog support (v0.5.2 ðŸ†•)
- ðŸ› ï¸ **Built-in Tools** - FileSystem, HTTP, DateTime, Math tools (v0.5.5 ðŸ†• convenient loading)
- ðŸ” **Tools Logging** - Comprehensive logging for built-in tools with security auditing (v0.5.6 ðŸ†•)
- ðŸŽ“ **Few-Shot Learning** - Teach agents with examples (inline or YAML personas) (v0.6.5 ðŸ†•)
- ðŸ¤” **ReAct Pattern** - Native function calling + text parsing modes for autonomous multi-step reasoning (v0.7.5 ðŸ†•)
- ðŸ§© **Planning Layer** - Goal decomposition, parallel execution, adaptive strategies for complex workflows (v0.7.1 ðŸ†•)
- ðŸš¦ **Rate Limiting** - Token bucket algorithm with per-key limits and burst capacity (v0.7.3 ðŸ†•)
- âœ… **Well Tested** - 1344+ tests, 71%+ coverage, 77+ working examples

## ðŸ“¦ Installation

```bash
go get github.com/taipm/go-deep-agent
```

## ðŸš€ Quick Start

### Simple Chat - One Line

```go
response, err := agent.NewOpenAI("gpt-4o-mini", apiKey).Ask(ctx, "What is Go?")
```

### With Streaming

```go
agent.NewOpenAI("gpt-4o-mini", apiKey).
    OnStream(func(content string) {
        fmt.Print(content)
    }).
    Stream(ctx, "Write a haiku about code")
```

### With Conversation Memory

```go
builder := agent.NewOpenAI("gpt-4o-mini", apiKey).WithMemory()

builder.Ask(ctx, "My name is John")
builder.Ask(ctx, "What's my name?")  // AI remembers: "Your name is John"
```

### With Custom Adapters (v0.7.9+)

**Use any LLM provider with the same Builder API!** Perfect for Gemini, Anthropic, custom endpoints, or testing:

```go
// âœ… Gemini Adapter (production ready)
import "github.com/taipm/go-deep-agent/agent/adapters"

geminiAdapter, err := adapters.NewGeminiAdapter("your-gemini-api-key")
if err != nil {
    log.Fatal(err)
}
defer geminiAdapter.Close()

response, err := agent.NewWithAdapter("gemini-pro", geminiAdapter).
    WithSystem("You are a helpful assistant").
    WithTemperature(0.7).
    Ask(ctx, "Explain quantum computing")

// âœ… Custom Mock Adapter (perfect for testing!)
type mockAdapter struct {
    responses []string
}

func (m *mockAdapter) Complete(ctx context.Context, req *agent.CompletionRequest) (*agent.CompletionResponse, error) {
    return &agent.CompletionResponse{Content: m.responses[0]}, nil
}

func (m *mockAdapter) Stream(ctx context.Context, req *agent.CompletionRequest, onChunk func(string)) (*agent.CompletionResponse, error) {
    return nil, fmt.Errorf("streaming not implemented")
}

func (m *mockAdapter) Close() error { return nil }

mock := &mockAdapter{responses: []string{"Hello from mock!"}}
response, err := agent.NewWithAdapter("mock-model", mock).
    WithSystem("You are a test assistant").
    Ask(ctx, "Test message")  // Returns: "Hello from mock!"
```

**Why Use Adapters?**
- ðŸ”„ **Same API**: All Builder features work with any provider
- ðŸ› ï¸ **Full Feature Support**: Tools, streaming, memory, validation, etc.
- âš¡ **Easy Testing**: Mock adapters for reliable unit tests
- ðŸ”Œ **Provider Agnostic**: Switch providers without changing code
- âœ… **Production Ready**: Error handling, timeouts, retries included

### With MultiProvider (v0.11.0+) - High Availability & Load Balancing

**Enterprise-grade provider management** with automatic failover, health monitoring, and intelligent load distribution:

```go
// âœ… BASIC: Simple multi-provider setup
providers := []agent.ProviderConfig{
    {
        Name:  "openai-primary",
        Type:  "openai",
        Model: "gpt-4o-mini",
        APIKey: os.Getenv("OPENAI_API_KEY"),
        Weight: 2.0,  // Higher weight = more traffic
    },
    {
        Name:  "ollama-backup",
        Type:  "ollama",
        Model: "llama2",
        BaseURL: "http://localhost:11434",
        Weight: 1.0,
    },
}

mp, err := agent.NewMultiProvider(&agent.MultiProviderConfig{
    Providers:         providers,
    SelectionStrategy:  agent.StrategyWeightedRoundRobin,  // Load balance by weight
    FallbackStrategy:   agent.FallbackStrategyCircuitBreaker,  // Auto-failover
    HealthCheckInterval: 30 * time.Second,                    // Monitor health
    EnableLoadBalancing: true,                                // Distribute load
    EnableMetrics:      true,                                 // Track performance
})
defer mp.Shutdown(ctx)

// Single API call - handles all provider management automatically
response, err := mp.Ask(ctx, "Hello from MultiProvider!")
// Automatically:
// - Selects best provider
// - Handles failures with fallback
// - Monitors health
// - Tracks metrics
```

#### ðŸŽ¯ **Advanced MultiProvider Features**

```go
// âœ… HEALTH MONITORING: Real-time provider health checks
healthStatus := mp.GetProviderStatus()
// Returns: map[string]agent.ProviderStatus{
//     "openai-primary": agent.ProviderStatusHealthy,
//     "ollama-backup":  agent.ProviderStatusDegraded,
// }

// âœ… CIRCUIT BREAKER: Automatic provider isolation
// When provider fails repeatedly, it's automatically isolated:
mp.AddProvider(agent.ProviderConfig{
    Name:    "flaky-provider",
    Type:    "adapter",
    Adapter: customAdapter,
})

// Circuit breaker opens after consecutive failures
// Provider automatically retried after timeout

// âœ… LOAD BALANCING: Intelligent traffic distribution
// Multiple strategies available:
- StrategyRoundRobin           // Equal distribution
- StrategyWeightedRoundRobin   // Weighted by capacity
- StrategyLeastConnections     // Send to least busy
- StrategyFastestResponse      // Route to fastest
- StrategyPriority             // Prioritized order
- StrategyRandom               // Random selection

// âœ… STICKY SESSIONS: Route same user to same provider
response, err := mp.SelectProviderForRequest(providers, "user-session-123")
    .Ask(ctx, "Hello")  // Always uses same provider for this session

// âœ… METRICS & MONITORING: Complete performance tracking
metrics := mp.GetMetrics()
for name, providerMetrics := range metrics {
    fmt.Printf("%s: %d requests, %.2f%% success, %s avg response\n",
        name,
        providerMetrics.TotalRequests,
        providerMetrics.UptimePercentage,
        providerMetrics.AverageResponseTime)
}

// âœ… DYNAMIC MANAGEMENT: Add/remove providers at runtime
mp.AddProvider(agent.ProviderConfig{
    Name:  "emergency-provider",
    Type:  "adapter",
    Adapter: emergencyAdapter,
    Weight: 0.5,  // Lower priority
})

mp.DisableProvider("maintenance-provider")
mp.EnableProvider("maintenance-provider")
mp.RemoveProvider("deprecated-provider")
```

#### ðŸš€ **Production MultiProvider Setup**

```go
// âœ… ENTERPRISE CONFIG: Full-featured setup
config := &agent.MultiProviderConfig{
    // Providers configuration
    Providers: []agent.ProviderConfig{
        // Primary: High-performance OpenAI
        {
            Name:    "openai-prod",
            Type:    "openai",
            Model:   "gpt-4o",
            APIKey:  os.Getenv("OPENAI_API_KEY"),
            Weight:  3.0,
            MaxConcurrency: 20,
            Timeout:        10 * time.Second,
        },
        // Secondary: Cost-effective Ollama
        {
            Name:    "ollama-cost-effective",
            Type:    "ollama",
            Model:   "llama3.2",
            Weight:  2.0,
            MaxConcurrency: 10,
            BaseURL: "http://ollama-cluster:11434",
        },
        // Backup: Local Gemini adapter
        {
            Name:    "gemini-local",
            Type:    "adapter",
            Model:   "gemini-pro",
            Adapter: geminiAdapter,
            Weight:  1.0,
            MaxConcurrency: 5,
        },
    },

    // Selection strategy
    SelectionStrategy: agent.StrategyWeightedRoundRobin,

    // Fallback with circuit breaker
    FallbackStrategy:      agent.FallbackStrategyCircuitBreaker,
    CircuitBreakerThreshold: 3,  // Open after 3 failures
    CircuitBreakerTimeout:   60 * time.Second,  // Retry after 1 minute

    // Health monitoring
    HealthCheckInterval: 15 * time.Second,  // Check every 15 seconds
    HealthCheckTimeout:  5 * time.Second,   // 5-second timeout

    // Load balancing
    EnableLoadBalancing: true,
    StickySessions:      true,  // Keep users on same provider

    // Observability
    EnableMetrics:        true,
    MetricsInterval:      30 * time.Second,
    LogLevel:             "info",
    EnableDetailedLogging: false,  // Enable for debugging only
}

mp, err := agent.NewMultiProvider(config)
if err != nil {
    log.Fatal("Failed to create MultiProvider:", err)
}
defer mp.Shutdown(ctx)

// ðŸŽ¯ Ready for production use!
// - Automatic failover
// - Health monitoring
// - Load distribution
// - Performance metrics
// - Dynamic management
```

**Why Use MultiProvider?**
- ðŸ›¡ï¸ **High Availability**: Automatic failover prevents downtime
- âš–ï¸ **Load Balancing**: Distribute traffic across multiple providers
- ðŸ’° **Cost Optimization**: Route requests to most cost-effective providers
- ðŸ¥ **Health Monitoring**: Real-time provider health checks
- ðŸ”„ **Circuit Breaker**: Isolate failing providers automatically
- ðŸ“Š **Performance Tracking**: Complete metrics and monitoring
- ðŸ”§ **Dynamic Management**: Add/remove providers without restart
- ðŸŽ¯ **Smart Routing**: Multiple selection strategies (weighted, priority, etc.)

### With Persistent Memory (v0.9.0+)

**Save conversations across program executions** - memories are automatically saved and restored:

#### File-Based (Built-in, Zero Config)

```go
// First conversation
agent := agent.NewOpenAI("gpt-4o-mini", apiKey).
    WithShortMemory().                    // Working memory (RAM)
    WithLongMemory("user-alice")          // Persistent memory (disk)

agent.Ask(ctx, "My favorite color is blue")
// Automatically saved to ~/.go-deep-agent/memories/user-alice.json

// Later (new program execution)
agent2 := agent.NewOpenAI("gpt-4o-mini", apiKey).
    WithShortMemory().
    WithLongMemory("user-alice")          // Auto-loads previous conversation

agent2.Ask(ctx, "What's my favorite color?")  // AI remembers: "Blue"
```

#### Redis Backend (v0.10.0+ - Production)

**For production deployments with shared memory across instances:**

```go
// âœ… RECOMMENDED: Simple setup
backend := agent.NewRedisBackend("localhost:6379")
defer backend.Close()

agent := agent.NewOpenAI("gpt-4o-mini", apiKey).
    WithShortMemory().
    WithLongMemory("user-alice").
    UsingBackend(backend)

// Conversations stored in Redis with 7-day TTL (auto-extends on activity)
agent.Ask(ctx, "My favorite color is blue")
```

**With authentication:**

```go
backend := agent.NewRedisBackend("localhost:6379").
    WithPassword("your-redis-password")

agent := agent.NewOpenAI("gpt-4o-mini", apiKey).
    WithShortMemory().
    WithLongMemory("user-alice").
    UsingBackend(backend)
```

**Custom configuration:**

```go
backend := agent.NewRedisBackend("localhost:6379").
    WithPassword("secret").
    WithTTL(24 * time.Hour).      // Expire after 24h of inactivity
    WithPrefix("myapp:")           // Custom key prefix

agent := agent.NewOpenAI("gpt-4o-mini", apiKey).
    WithShortMemory().
    WithLongMemory("user-alice").
    UsingBackend(backend)
```

**Key Features:**
- ðŸ’¾ **Auto-save** - Automatically persists after each `Ask()` or `Stream()`
- ðŸ”„ **Auto-load** - Restores previous conversations on initialization
- ðŸª **File-based** - Zero dependencies, works out-of-the-box (`~/.go-deep-agent/memories/`)
- ðŸ”´ **Redis backend** - Production-ready with clustering, TTL, and connection pooling
- ðŸ”Œ **Pluggable** - Custom backends (PostgreSQL, S3, etc.)
- ðŸ”’ **Thread-safe** - Concurrent access with atomic writes
- â®ï¸ **Backward compatible** - Old API still works with deprecation warnings

**Manual Control:**

```go
agent := agent.NewOpenAI("gpt-4o-mini", apiKey).
    WithShortMemory().
    WithLongMemory("user-bob").
    WithAutoSaveLongMemory(false)  // Manual mode

// Manual operations
agent.SaveLongMemory(ctx)                  // Save explicitly
agent.LoadLongMemory(ctx)                  // Reload from storage
agent.DeleteLongMemory(ctx)                // Remove memory
memories, _ := agent.ListLongMemories(ctx) // List all memories
```

**ðŸ“– Guides:**
- **[Redis Backend Guide](docs/REDIS_BACKEND_GUIDE.md)** - Installation, configuration, best practices (v0.10.1 updated)
- **[Memory System Guide](RELEASE_NOTES_v0.9.0.md)** - Memory terminology, migration from v0.8.0

### With Few-Shot Learning (v0.6.5 ðŸ†•)

```go
ai := agent.NewOpenAI("gpt-4o-mini", apiKey).
    WithSystem("You are a French translator.").
    AddFewShotExample("Translate: Hello", "Bonjour").
    AddFewShotExample("Translate: Goodbye", "Au revoir")

ai.Ask(ctx, "Translate: Good morning")  // AI follows the pattern
```

**[ðŸ“– Few-Shot Learning Guide](docs/FEWSHOT_GUIDE.md)** - Selection modes, YAML personas, best practices

### With Production Defaults (v0.5.8 ðŸ†•)

**The easiest way to get started** - one method call for production-ready configuration:

```go
// WithDefaults() gives you: Memory(20), Retry(3), Timeout(30s), ExponentialBackoff
ai := agent.NewOpenAI("gpt-4o-mini", apiKey).WithDefaults()

// Now you're ready for production use with smart defaults
resp, _ := ai.Ask(ctx, "Hello!")
```

**Customize defaults via method chaining:**

```go
ai := agent.NewOpenAI("gpt-4", apiKey).
    WithDefaults().          // Start with smart defaults
    WithMaxHistory(50).      // Customize: Increase memory
    WithTools(myTool).       // Add: Tool capability
    WithLogging(logger)      // Add: Observability

resp, _ := ai.Ask(ctx, "Complex task...")
```

**Philosophy: Bare â†’ WithDefaults() â†’ Customize**

- **Bare**: `NewOpenAI(model, key)` - Full control, zero configuration
- **WithDefaults()**: Production-ready in one line (80% use cases)
- **Customize**: Progressive enhancement via method chaining

### Production-Ready Configuration

```go
response, err := agent.NewOpenAI("gpt-4o-mini", apiKey).
    WithSystem("You are a helpful assistant").
    WithTemperature(0.7).
    WithMaxTokens(500).
    WithMemory().
    WithMaxHistory(10).
    WithTimeout(30 * time.Second).
    WithRetry(3).
    WithExponentialBackoff().
    Ask(ctx, "Explain Go concurrency")
```

## ðŸ“– Builder API Examples

### 1. OpenAI with System Prompt

```go
response, err := agent.NewOpenAI("gpt-4o-mini", apiKey).
    WithSystem("You are a helpful assistant").
    WithTemperature(0.7).
    Ask(ctx, "Explain quantum computing")
```

### 2. Streaming with Callbacks

```go
response, err := agent.NewOpenAI("gpt-4o-mini", apiKey).
    OnStream(func(content string) {
        fmt.Print(content)  // Print each chunk as it arrives
    }).
    Stream(ctx, "Write a haiku about AI")
```

### 3. Conversation Memory

```go
builder := agent.NewOpenAI("gpt-4o-mini", apiKey).
    WithMemory().           // Enable automatic memory
    WithMaxHistory(10)      // Keep last 10 messages (auto-truncate)

// First message
builder.Ask(ctx, "My name is John and I'm from Vietnam")

// AI remembers previous context
builder.Ask(ctx, "What's my name and where am I from?")
// Response: "Your name is John and you're from Vietnam"
```

### 3.1 Hierarchical Memory (v0.6.0 ðŸ†•)

**3-tier intelligent memory system**: Working â†’ Episodic â†’ Semantic

```go
// Automatic episodic storage for important messages
builder := agent.NewOpenAI("gpt-4o-mini", apiKey).
    WithEpisodicMemory(0.7).           // Store messages with importance >= 0.7
    WithWorkingMemorySize(20).          // Working capacity
    WithSemanticMemory()                // Enable fact storage

// Important messages automatically stored in episodic memory
builder.Ask(ctx, "Remember: my birthday is Jan 15")  // importance: 1.0 â†’ episodic
builder.Ask(ctx, "How's the weather?")               // importance: 0.1 â†’ working only

// Recall from episodic memory
episodes := builder.GetMemory().Recall(ctx, "birthday", 5)

// Get detailed stats
stats := builder.GetMemory().Stats(ctx)
fmt.Printf("Working: %d, Episodic: %d, Semantic: %d\n", 
    stats.WorkingSize, stats.EpisodicSize, stats.SemanticSize)
```

**Importance weights** (customizable):
```go
builder := agent.NewOpenAI("gpt-4o-mini", apiKey).
    WithImportanceWeights(agent.ImportanceWeights{
        RememberKeyword: 1.0,  // "Remember this", "Don't forget"
        PersonalInfo:    0.8,  // Names, dates, locations
        Question:        0.3,  // Questions from user
        Answer:          0.2,  // Answers from assistant
    })
```

ðŸ“š **See migration guide**: [docs/MEMORY_MIGRATION.md](docs/MEMORY_MIGRATION.md)

### 4. Tool Calling with Auto-Execution

```go
weatherTool := agent.NewTool("get_weather", "Get current weather").
    AddParameter("location", "string", "City name", true).
    WithHandler(func(args string) (string, error) {
        return `{"temp": 25, "condition": "sunny"}`, nil
    })

response, err := agent.NewOpenAI("gpt-4o-mini", apiKey).
    WithTools(weatherTool).
    WithAutoExecute(true).  // Automatically execute tool calls
    Ask(ctx, "What's the weather in Hanoi?")
```

### 5. Structured Outputs (JSON Schema)

```go
schema := map[string]interface{}{
    "type": "object",
    "properties": map[string]interface{}{
        "name": map[string]interface{}{"type": "string"},
        "age":  map[string]interface{}{"type": "integer"},
    },
    "required":             []string{"name", "age"},
    "additionalProperties": false,
}

response, err := agent.NewOpenAI("gpt-4o-mini", apiKey).
    WithJSONSchema("person_info", "Extract person info", schema, true).
    Ask(ctx, "John is 25 years old")
// Response: {"name":"John","age":25}
```

### 6. Error Handling with Retry

```go
response, err := agent.NewOpenAI("gpt-4o-mini", apiKey).
    WithTimeout(10 * time.Second).
    WithRetry(3).
    WithExponentialBackoff().  // 1s, 2s, 4s, 8s delays
    Ask(ctx, "What is Go?")

if err != nil {
    if agent.IsTimeoutError(err) {
        log.Println("Request timed out")
    } else if agent.IsRateLimitError(err) {
        log.Println("Rate limit exceeded")
    }
}
```

### 7. Rate Limiting (v0.7.3 ðŸ†•)

**Control request rates to comply with API limits and manage costs:**

```go
// Simple rate limiting: 10 requests/second, burst of 20
ai := agent.NewOpenAI("gpt-4o-mini", apiKey).
    WithRateLimit(10.0, 20).
    WithMemory()

// Make requests - automatically throttled
for i := 0; i < 100; i++ {
    ai.Ask(ctx, fmt.Sprintf("Question %d", i))
    // First 20 requests use burst capacity (immediate)
    // Remaining requests throttled to 10/second
}
```

**Per-user rate limiting for multi-tenant applications:**

```go
config := agent.RateLimitConfig{
    Enabled:           true,
    RequestsPerSecond: 5.0,
    BurstSize:         10,
    PerKey:            true,  // Independent limits per key
    KeyTimeout:        5 * time.Minute,
}

// Different users get independent rate limits
aiUser1 := agent.NewOpenAI("gpt-4o-mini", apiKey).
    WithRateLimitConfig(config).
    WithRateLimitKey("user-123")  // User 1's quota

aiUser2 := agent.NewOpenAI("gpt-4o-mini", apiKey).
    WithRateLimitConfig(config).
    WithRateLimitKey("user-456")  // User 2's quota (independent)
```

**[ðŸ“– Rate Limiting Guide](docs/RATE_LIMITING_GUIDE.md)** - Algorithms, best practices, Redis backend

### 8. Using Ollama (Local LLM)

```go
// Simple usage - default base URL is http://localhost:11434/v1
response, err := agent.NewOllama("qwen2.5:3b").
    Ask(ctx, "What is Go?")

// With configuration
response, err := agent.NewOllama("qwen2.5:3b").
    WithSystem("You are a concise assistant").
    WithTemperature(0.8).
    WithMemory().
    Ask(ctx, "Explain goroutines")
```

### 9. ReAct Pattern - Native Function Calling (v0.7.5 ðŸ†•)

**ReAct (Reasoning + Acting)** with **native function calling** for reliable tool execution:

```go
// Define tools
calculator := agent.NewTool("calculator", "Perform calculations").
    WithHandler(calcHandler)
search := agent.NewTool("search", "Search the web").
    WithHandler(searchHandler)

// Enable ReAct with task complexity (v0.7.6+ recommended)
ai := agent.NewOpenAI("gpt-4o", apiKey).
    WithTools(calculator, search).
    WithReActMode(true).         // Enable ReAct pattern  
    WithReActComplexity(agent.ReActTaskMedium). // Auto-configure for medium tasks

// Execute complex multi-step task
result, _ := ai.Ask(ctx, "What is 15 * 7 and what's the weather in Paris?")

// The agent autonomously:
// 1. Thought: "First I'll calculate 15 * 7"
// 2. Action: calculator("15 * 7")
// 3. Observation: "105"
// 4. Thought: "Now I need Paris weather"
// 5. Action: search("Paris weather")
// 6. Observation: "15Â°C, Cloudy"
// 7. Answer: "15 * 7 = 105. Weather in Paris is 15Â°C and cloudy."

// Access full reasoning trace
reactResult := result.Metadata["react_result"].(*agent.ReActResult)
for i, step := range reactResult.Steps {
    fmt.Printf("[Step %d] %s: %s\n", i+1, step.Type, step.Content)
}
```

#### Task Complexity Levels (v0.7.6+)

Choose the right complexity for better UX:

```go
// Simple tasks: 3 iterations, 30s timeout
ai := agent.NewOpenAI("gpt-4o-mini", apiKey).
    WithReActMode(true).
    WithReActComplexity(agent.ReActTaskSimple).
    WithTools(mathTool)
// Use for: Single calculation, direct lookup, simple queries

// Medium tasks: 5 iterations, 60s timeout  
ai := agent.NewOpenAI("gpt-4o-mini", apiKey).
    WithReActMode(true).
    WithReActComplexity(agent.ReActTaskMedium).
    WithTools(mathTool, searchTool)
// Use for: Multi-step reasoning, 2-3 tool calls, analysis

// Complex tasks: 10 iterations, 120s timeout
ai := agent.NewOpenAI("gpt-4o-mini", apiKey).
    WithReActMode(true).
    WithReActComplexity(agent.ReActTaskComplex).
    WithTools(mathTool, searchTool, dbTool)
// Use for: Advanced reasoning, multiple tools, complex workflows
```

**Features:**

- âœ… Autonomous multi-step reasoning
- âœ… Tool orchestration (chains multiple tools naturally)
- âœ… Auto-fallback on max iterations (v0.7.6+)
- âœ… Progressive urgency reminders (v0.7.6+)
- âœ… Rich error messages with debugging info (v0.7.6+)
- âœ… Transparent reasoning (full trace of thoughts and actions)
- âœ… Streaming support for real-time progress

**[ðŸ“– ReAct Pattern Guide](docs/guides/REACT_GUIDE.md)** - Full documentation, best practices, and advanced features

**[ðŸš€ Native ReAct Examples](examples/react_native/)** - Comprehensive demos showing native function calling

**[ðŸ”§ Troubleshooting](docs/REACT_TROUBLESHOOTING.md)** - Common issues and solutions (v0.7.6+)

### 9. Planning Layer - Complex Workflows (v0.7.1 ðŸ†•)

**Goal-oriented planning** with automatic task decomposition, dependency management, and adaptive execution:

```go
// High-level API - automatic planning and execution
result, _ := agent.NewOpenAI("gpt-4o", apiKey).
    PlanAndExecute(ctx, "Research AI trends and write a comprehensive report")

// The agent autonomously:
// 1. Decomposes goal into tasks (research, analyze, synthesize, write)
// 2. Manages dependencies (can't write before research)
// 3. Executes in optimal order (parallel when possible)
// 4. Tracks progress and metrics

fmt.Printf("Completed %d tasks in %v\n",
    result.Metrics.TaskCount,
    result.Metrics.ExecutionTime)

// Advanced: Manual control with custom strategies
plan := agent.NewPlan("ETL Pipeline", agent.StrategyParallel)
plan.AddTask(agent.Task{ID: "extract-1", Description: "Extract from DB1"})
plan.AddTask(agent.Task{ID: "extract-2", Description: "Extract from DB2"})
plan.AddTask(agent.Task{
    ID:           "transform",
    Description:  "Transform combined data",
    Dependencies: []string{"extract-1", "extract-2"}, // Wait for both
})

config := agent.DefaultPlannerConfig()
config.MaxParallel = 10                    // 10 concurrent tasks
config.Strategy = agent.StrategyAdaptive   // Auto-optimize

executor := agent.NewExecutor(config, aiAgent)
result, _ := executor.Execute(ctx, plan)

// Monitor execution
for _, event := range result.Timeline {
    fmt.Printf("[%v] %s\n", event.Timestamp, event.Description)
}
```

**Features:**

- âœ… **3 Execution Strategies**: Sequential, Parallel, Adaptive (auto-switching)
- âœ… **Dependency Management**: Direct, transitive, diamond patterns, cycle detection
- âœ… **Goal-Oriented**: Early termination when goals met
- âœ… **Performance**: ~8.4Âµs topological sort, 97.6 tasks/sec throughput (parallel)
- âœ… **Monitoring**: Timeline events, metrics (success rate, latency, efficiency)
- âœ… **Production-Ready**: Timeout, cancellation, error recovery

**When to Use:**

| Use Case | Strategy | Example |
|----------|----------|---------|
| Simple workflow (< 5 tasks) | Sequential | Setup â†’ Configure â†’ Execute |
| Batch processing | Parallel | Process 100 items concurrently |
| Multi-phase pipeline | Adaptive | Research (parallel) â†’ Analyze (sequential) â†’ Report |
| Complex dependencies | Sequential | Long dependency chains |

**[ðŸ“– Planning Guide](docs/PLANNING_GUIDE.md)** - Concepts, patterns, best practices  
**[ðŸ“– Planning API](docs/PLANNING_API.md)** - Complete API reference  
**[ðŸ“– Planning Performance](docs/PLANNING_PERFORMANCE.md)** - Benchmarks, optimization, tuning

### 10. Redis Cache - Distributed Caching (v0.5.1 ðŸ†•)

```go
// Simple Redis cache setup
ai := agent.NewOpenAI("gpt-4o-mini", apiKey).
    WithRedisCache("localhost:6379", "", 0)

// First call - cache miss (~1-2s)
resp1, _ := ai.Ask(ctx, "What is Go?")

// Second call - cache hit (~5ms, 200x faster!)
resp2, _ := ai.Ask(ctx, "What is Go?")

// Check cache statistics
stats := ai.GetCacheStats()
fmt.Printf("Hit rate: %.2f%%\n",
    float64(stats.Hits)/(float64(stats.Hits+stats.Misses))*100)

// Advanced configuration
opts := &agent.RedisCacheOptions{
    Addrs:       []string{"localhost:6379"},
    Password:    "your-redis-password",
    PoolSize:    20,                 // Connection pool
    KeyPrefix:   "myapp",            // Namespace
    DefaultTTL:  10 * time.Minute,   // Cache expiration
}

ai := agent.NewOpenAI("gpt-4o-mini", apiKey).
    WithRedisCacheOptions(opts)

// Custom TTL per request
ai.WithCacheTTL(1 * time.Hour).Ask(ctx, "Historical facts")

// Redis Cluster support
opts := &agent.RedisCacheOptions{
    Addrs: []string{
        "redis-node1:6379",
        "redis-node2:6379",
        "redis-node3:6379",
    },
    Password: "cluster-password",
}
```

**Benefits:**

- Shared cache across multiple instances
- Persistent cache (survives restarts)
- Distributed locking (prevents cache stampede)
- Scalable with Redis Cluster

### 10. Logging & Observability (v0.5.2 ðŸ†•)

```go
// Debug logging for development
builder := agent.NewOpenAI("gpt-4o-mini", apiKey).
    WithDebugLogging() // Detailed logs with timing, cache, tools, RAG

response, err := builder.Ask(ctx, "Hello!")
// Output:
// [2024-01-15 10:30:45] DEBUG: Ask request started | model=gpt-4o-mini
// [2024-01-15 10:30:45] DEBUG: Cache miss | duration_ms=2
// [2024-01-15 10:30:46] INFO: Ask completed | duration_ms=890 tokens=23

// Info logging for production
builder := agent.NewOpenAI("gpt-4o-mini", apiKey).
    WithInfoLogging() // Important events only

// Slog integration (Go 1.21+)
handler := slog.NewJSONHandler(os.Stdout, &slog.HandlerOptions{
    Level: slog.LevelInfo,
})
logger := slog.New(handler)

builder := agent.NewOpenAI("gpt-4o-mini", apiKey).
    WithLogger(agent.NewSlogAdapter(logger))
// Output: {"time":"...","level":"INFO","msg":"Ask completed","duration_ms":890}

// Custom logger (Zap, Logrus, etc.)
type MyLogger struct { /* implement Logger interface */ }
builder := agent.NewOpenAI("gpt-4o-mini", apiKey).
    WithLogger(&MyLogger{})

// No logging (default - zero overhead)
builder := agent.NewOpenAI("gpt-4o-mini", apiKey)
// NoopLogger - literally zero cost
```

**What gets logged:**

- Request lifecycle (start, duration, completion)
- Token usage (prompt, completion, total)
- Cache operations (hit/miss, duration)
- Tool execution (rounds, tool calls, results)
- RAG retrieval (docs retrieved, method)
- Retry attempts (delays, errors)
- Errors with context

ðŸ“– **[Complete Logging Guide](docs/LOGGING_GUIDE.md)** - Custom loggers, slog integration, production best practices

### 11. Built-in Tools (v0.5.5 ðŸ†• Convenient Loading)

go-deep-agent provides 4 production-ready built-in tools. **v0.5.5** introduces convenient helpers for easy loading:

#### Quick Start - Safe Tools by Default

```go
import (
    "github.com/taipm/go-deep-agent/agent"
    "github.com/taipm/go-deep-agent/agent/tools"
)

// Option 1: Load safe tools (DateTime + Math) - RECOMMENDED â­
ai := tools.WithDefaults(agent.NewOpenAI("gpt-4o", apiKey)).
    WithAutoExecute(true)

// Option 2: Load all tools (includes file & network access) - Use with caution
ai := tools.WithAll(agent.NewOpenAI("gpt-4o", apiKey)).
    WithAutoExecute(true)

// Option 3: Manual selection (full control)
ai := agent.NewOpenAI("gpt-4o", apiKey).
    WithTools(tools.NewDateTimeTool(), tools.NewMathTool()).
    WithAutoExecute(true)
```

**Why `WithDefaults()`?** (v0.5.5)
- âœ… **Safe**: DateTime and Math have no file/network access
- âœ… **No side effects**: Read-only time, pure math computations
- âœ… **Core capabilities**: Nearly every AI agent needs time context and math
- âœ… **One-liner**: Get started quickly with sensible defaults

**Why FileSystem/HTTP remain opt-in?**
- âš ï¸ **Powerful but risky**: Can read/write files, make external requests
- âš ï¸ **Explicit consent**: User should know agent has these capabilities
- âš ï¸ **Principle of least privilege**: Only grant what's needed

#### 10.1 FileSystem Tool (Opt-in for security)

#### 10.1 FileSystem Tool (Opt-in for security)

File operations with path traversal prevention.

```go
fsTool := tools.NewFileSystemTool()

ai := agent.NewOpenAI("gpt-4o", apiKey).
    WithTool(fsTool).  // Explicitly add for security awareness
    WithAutoExecute(true)

response, _ := ai.Ask(ctx, "Read config.json and list all JSON files in current directory")
```

**Operations** (7 total):
- `read_file`, `write_file`, `append_file`, `delete_file`
- `list_directory`, `file_exists`, `create_directory`
- **Security**: Path traversal prevention (`../` blocked)

#### 10.2 HTTP Tool (Opt-in for security)

Full HTTP client for API requests.

```go
httpTool := tools.NewHTTPRequestTool()

ai := agent.NewOpenAI("gpt-4o", apiKey).
    WithTool(httpTool).  // Explicitly add for security awareness
    WithAutoExecute(true)

response, _ := ai.Ask(ctx, "Fetch https://api.github.com/users/github and summarize")
```

**Features**:
- Methods: GET, POST, PUT, DELETE
- Custom headers, timeout (default 30s)
- JSON parsing

#### 10.3 DateTime Tool (Safe - auto-loadable via WithDefaults)

Date/time operations with timezone support.

```go
// Auto-loaded with WithDefaults(), or manually:
dtTool := tools.NewDateTimeTool()

ai := agent.NewOpenAI("gpt-4o", apiKey).
    WithTool(dtTool).
    WithAutoExecute(true)

response, _ := ai.Ask(ctx, "What day of the week is Christmas 2025 in Tokyo timezone?")
```

**Operations** (7 total):
- `current_time`, `format_date`, `parse_date`
- `add_duration`, `date_diff`, `convert_timezone`, `day_of_week`
- **Timezones**: UTC, America/New_York, Asia/Tokyo, etc.
- **Safe**: Read-only, no side effects

#### 10.4 Math Tool (Safe - auto-loadable via WithDefaults)

Professional-grade math powered by **govaluate** + **gonum**.

#### 10.4 Math Tool (Safe - auto-loadable via WithDefaults)

Professional-grade math powered by **govaluate** + **gonum**.

```go
// Auto-loaded with WithDefaults(), or manually:
mathTool := tools.NewMathTool()

ai := agent.NewOpenAI("gpt-4o", apiKey).
    WithTool(mathTool).
    WithAutoExecute(true)

// Expression evaluation (11 functions)
ai.Ask(ctx, "Calculate: 2 * (3 + 4) + sqrt(16)")
// Functions: sqrt, pow, sin, cos, tan, log, ln, abs, ceil, floor, round

// Statistics (gonum/stat)
ai.Ask(ctx, "What's the average of 10, 20, 30, 40, 50?")
// Measures: mean, median, stdev, variance, min, max, sum

// Equation solving
ai.Ask(ctx, "Solve: x+15=42")

// Unit conversion
ai.Ask(ctx, "Convert 100 km to meters")

// Random generation
ai.Ask(ctx, "Pick a random number from 1 to 100")
```

**Operations** (5 categories):
- **evaluate**: Expressions with 11 functions (govaluate engine)
- **statistics**: 7 measures (gonum library)
- **solve**: Linear equations (quadratic coming v0.6.0)
- **convert**: Distance, weight, temperature, time
- **random**: Integer, float, choice

**Safe**: Pure computations, no I/O operations  
**Dependencies**: +9MB binary for professional accuracy

ðŸ“– **[View builtin_tools_demo.go](examples/builtin_tools_demo.go)** - Complete examples  
ðŸ“– **[View test_with_defaults.go](examples/test_with_defaults.go)** - v0.5.5 WithDefaults() usage

### 12. History Management

```go
builder := agent.NewOpenAI("gpt-4o-mini", apiKey).WithMemory()

builder.Ask(ctx, "I love Go programming")
builder.Ask(ctx, "What are channels?")

// Get conversation history
history := builder.GetHistory()
fmt.Printf("Messages: %d\n", len(history))

// Clear conversation (keeps system prompt)
builder.Clear()

// Save and restore sessions
savedHistory := builder.GetHistory()
// ... later ...
builder.SetHistory(savedHistory)
```

### 13. Multimodal - Vision (GPT-4 Vision)

```go
// Analyze image from URL
response, err := agent.NewOpenAI("gpt-4o-mini", apiKey).
    WithImage("https://example.com/photo.jpg").
    Ask(ctx, "What do you see in this image?")

// Compare multiple images with detail control
response, err := agent.NewOpenAI("gpt-4o-mini", apiKey).
    WithImageURL("https://example.com/image1.jpg", agent.ImageDetailLow).
    WithImageURL("https://example.com/image2.jpg", agent.ImageDetailHigh).
    Ask(ctx, "Compare these two images")

// Analyze local image file
response, err := agent.NewOpenAI("gpt-4o-mini", apiKey).
    WithImageFile("./chart.png", agent.ImageDetailHigh).
    Ask(ctx, "Extract data from this chart")

// Conversation with images
builder := agent.NewOpenAI("gpt-4o-mini", apiKey).WithMemory()
builder.WithImage("https://example.com/photo.jpg").
    Ask(ctx, "What's in this image?")
builder.Ask(ctx, "What colors are prominent?") // Remembers the image
```

### 14. Vector RAG - Semantic Search (v0.5.0 ðŸ†•)

```go
// Setup vector database and embeddings
embedding, _ := agent.NewOllamaEmbedding(
    "http://localhost:11434",
    "nomic-embed-text", // Free local embeddings
)

store, _ := agent.NewChromaStore("http://localhost:8000")
store.WithEmbedding(embedding)

// Create collection
config := &agent.CollectionConfig{
    Name:           "company-kb",
    Dimension:      768,
    DistanceMetric: agent.DistanceMetricCosine,
}
store.CreateCollection(ctx, "company-kb", config)

// Create agent with vector RAG
ai := agent.NewOpenAI("gpt-4o-mini", apiKey).
    WithVectorRAG(embedding, store, "company-kb").
    WithRAGTopK(3).         // Retrieve top 3 similar docs
    WithMemory()

// Add knowledge base
docs := []string{
    "Our refund policy allows full refunds within 30 days.",
    "Customer support is available 24/7 at support@company.com.",
    "We support integrations with Slack, Teams, and Salesforce.",
}
ai.AddDocumentsToVector(ctx, docs...)

// Ask questions - semantically retrieves relevant context
response, _ := ai.Ask(ctx, "What is your refund policy?")
fmt.Println(response)

// See what was retrieved
retrieved := ai.GetLastRetrievedDocs()
for _, doc := range retrieved {
    fmt.Printf("Score: %.3f | %s\n", doc.Score, doc.Content)
}
```

### 15. Advanced Vector RAG with Metadata

```go
// Add documents with rich metadata
vectorDocs := []*agent.VectorDocument{
    {
        Content: "Python is great for data science and machine learning.",
        Metadata: map[string]interface{}{
            "category":   "programming",
            "language":   "Python",
            "difficulty": "beginner",
            "tags":       []string{"data-science", "ml"},
        },
    },
    {
        Content: "Go is excellent for building high-performance backend services.",
        Metadata: map[string]interface{}{
            "category":   "programming",
            "language":   "Go",
            "difficulty": "intermediate",
            "tags":       []string{"backend", "concurrency"},
        },
    },
}

ai.AddVectorDocuments(ctx, vectorDocs...)

// Query with custom config
ai := agent.NewOpenAI("gpt-4o-mini", apiKey).
    WithVectorRAG(embedding, store, "docs").
    WithRAGConfig(&agent.RAGConfig{
        TopK:          5,     // Retrieve top 5
        MinScore:      0.7,   // Only high-confidence results
        IncludeScores: true,  // Show relevance scores
    })

response, _ := ai.Ask(ctx, "Tell me about backend programming")

// Access retrieved metadata
docs := ai.GetLastRetrievedDocs()
for _, doc := range docs {
    fmt.Printf("Language: %s, Difficulty: %s\n",
        doc.Metadata["language"],
        doc.Metadata["difficulty"])
}
```

### 16. Switch Vector Databases - ChromaDB vs Qdrant

```go
// Development: Use ChromaDB (easy setup)
chromaStore, _ := agent.NewChromaStore("http://localhost:8000")
aiDev := agent.NewOpenAI("gpt-4o-mini", apiKey).
    WithVectorRAG(embedding, chromaStore, "docs")

// Production: Use Qdrant (high performance)
qdrantStore, _ := agent.NewQdrantStore("http://localhost:6333")
qdrantStore.WithAPIKey("your-api-key") // Optional
aiProd := agent.NewOpenAI("gpt-4o-mini", apiKey).
    WithVectorRAG(embedding, qdrantStore, "docs")

// Both use the same API - seamless switching!
```

## ðŸ“– Builder API Methods

### Core Methods

- `NewOpenAI(model, apiKey)` - Create OpenAI builder
- `NewOllama(model)` - Create Ollama builder (localhost:11434)
- `New(provider, model)` - Generic constructor
- `Ask(ctx, message)` - Send message, get response
- `Stream(ctx, message)` - Stream response with callbacks
- `StreamPrint(ctx, message)` - Stream and print to stdout

### Configuration

- `WithAPIKey(key)` - Set API key
- `WithBaseURL(url)` - Custom endpoint
- `WithModel(model)` - Change model
- `WithSystem(prompt)` - System prompt
- `WithTemperature(temp)` - Sampling temperature (0-2)
- `WithTopP(topP)` - Nucleus sampling (0-1)
- `WithMaxTokens(max)` - Maximum tokens to generate
- `WithPresencePenalty(penalty)` - Presence penalty (-2 to 2)
- `WithFrequencyPenalty(penalty)` - Frequency penalty (-2 to 2)
- `WithSeed(seed)` - For reproducible outputs
- `WithN(n)` - Number of completions to generate

### Conversation Management

- `WithMemory()` - Enable automatic conversation memory
- `WithMaxHistory(max)` - Limit messages (FIFO truncation)
- `WithEpisodicMemory(threshold)` - Enable episodic storage (0.0-1.0)
- `WithWorkingMemorySize(size)` - Set working memory capacity
- `WithImportanceWeights(weights)` - Customize importance calculation
- `WithSemanticMemory()` - Enable fact storage
- `GetMemory()` - Access memory system for advanced operations
- `DisableMemory()` - Disable hierarchical memory (use simple FIFO)
- `GetHistory()` - Get conversation messages
- `SetHistory(messages)` - Restore conversation
- `Clear()` - Reset conversation (keeps system prompt)

### Tool Calling

- `WithTools(tools...)` - Register tools/functions
- `WithAutoExecute(enable)` - Auto-execute tool calls
- `WithMaxToolRounds(max)` - Max execution rounds (default 5)
- `WithToolChoice(choice)` - Control when LLM uses tools (v0.7.8 ðŸ†•)
  - `"auto"` - Let LLM decide (default)
  - `"required"` - Force tool usage (compliance, audit trails)
  - `"none"` - Disable tools temporarily
- `OnToolCall(callback)` - Tool call callback

**Tool Choice Control** (v0.7.8) - Fine-grained control over tool usage:

```go
// REQUIRED mode: Force tool usage for compliance
builder := agent.NewOpenAI("gpt-4o", apiKey).
    WithTools(calculatorTool).
    WithAutoExecute(true).
    WithToolChoice("required").  // Guarantee tool execution
    Ask(ctx, "Calculate total: 1000 shares at $750.50")
// âœ“ Calculation verified via tool - audit trail available
```

Use cases:
- **Compliance**: Financial calculations, legal verification, healthcare data (auditable)
- **Quality Control**: Guarantee 100% accurate data via tool verification
- **API Integration**: Force real-time data retrieval, prevent hallucination
- **Security**: Mandatory verification steps
- **Testing**: `"none"` mode to test LLM reasoning without tools

### Multimodal Support (Vision)

- `WithImage(url)` - Add image with auto detail level
- `WithImageURL(url, detail)` - Add image with specific detail (Low/High)
- `WithImageFile(filePath, detail)` - Add local image file
- `WithImageBase64(base64Data, mimeType, detail)` - Add base64-encoded image
- `ClearImages()` - Remove pending images

Supported models: `gpt-4o`, `gpt-4o-mini`, `gpt-4-turbo`, `gpt-4-vision-preview`

### Structured Outputs

- `WithJSONMode()` - Force JSON output
- `WithJSONSchema(name, desc, schema, strict)` - Structured JSON

### Streaming Callbacks

- `OnStream(callback)` - Content chunk callback
- `OnRefusal(callback)` - Refusal detection callback

### Error Handling & Recovery

- `WithTimeout(duration)` - Request timeout
- `WithRetry(maxRetries)` - Retry failed requests
- `WithRetryDelay(delay)` - Fixed delay between retries
- `WithExponentialBackoff()` - Use exponential backoff

### Error Codes & Debugging (v0.5.9 ðŸ†•)

**Error Codes** for programmatic decisions:

- `GetErrorCode(err)` - Extract error code from any error
- `IsCodedError(err)` - Check if error has a code
- `NewCodedError(code, msg, err)` - Create coded error
- **20+ error codes** including: `ErrCodeRateLimitExceeded`, `ErrCodeRequestTimeout`, `ErrCodeAPIKeyMissing`, etc.

**Debug Mode** for visibility:

- `WithDebug(config)` - Enable debug logging with secret redaction
- `DefaultDebugConfig()` - Basic logging (production-safe)
- `VerboseDebugConfig()` - Full logging (development)
- **Auto secret redaction**: API keys, tokens, passwords automatically masked

**Panic Recovery** for stability:

- `IsPanicError(err)` - Check if error is from panic
- `GetPanicValue(err)` - Extract panic value
- `GetStackTrace(err)` - Get full stack trace
- **Automatic recovery**: Tool panics are caught and returned as errors

**Error Context** for debugging:

- `WithContext(err, operation, details)` - Add context to errors
- `WithSimpleContext(err, operation)` - Quick context without details
- `SummarizeError(err)` - Get comprehensive error summary
- `NewErrorChain()` - Track multiple errors in workflows

See [ERROR_HANDLING_BEST_PRACTICES.md](docs/ERROR_HANDLING_BEST_PRACTICES.md) for complete guide.

### Error Type Checking

- `IsAPIKeyError(err)` - Check for API key errors
- `IsRateLimitError(err)` - Check for rate limits
- `IsTimeoutError(err)` - Check for timeouts
- `IsRefusalError(err)` - Check for content refusals
- `IsInvalidResponseError(err)` - Check for invalid responses
- `IsMaxRetriesError(err)` - Check if retries exhausted
- `IsToolExecutionError(err)` - Check for tool errors

### Vector RAG (v0.5.0 ðŸ†•)

- `WithVectorRAG(embedding, store, collection)` - Enable vector-based RAG
- `AddDocumentsToVector(ctx, docs...)` - Add string documents to vector store
- `AddVectorDocuments(ctx, vectorDocs...)` - Add documents with metadata
- `GetLastRetrievedDocs()` - Get retrieved documents with scores

### Response Caching (v0.4.0, v0.5.1 ðŸ†•)

- `WithCache(cache)` - Set custom cache implementation
- `WithMemoryCache(maxSize, defaultTTL)` - In-memory LRU cache
- `WithRedisCache(addr, password, db)` - Redis distributed cache (simple)
- `WithRedisCacheOptions(opts)` - Redis cache with advanced config
- `WithCacheTTL(ttl)` - Set custom TTL for next request
- `DisableCache()` - Temporarily disable caching
- `EnableCache()` - Re-enable caching
- `GetCacheStats()` - Retrieve cache statistics (hits, misses, hit rate)
- `ClearCache(ctx)` - Clear all cached responses

### Embedding Providers (v0.5.0 ðŸ†•)

- `NewOllamaEmbedding(baseURL, model)` - Free local embeddings (Ollama)
- `NewOpenAIEmbedding(apiKey, model, dimension)` - OpenAI embeddings
- `Generate(ctx, texts)` - Generate embeddings for texts
- `GenerateQuery(ctx, query)` - Generate embedding for search query

### Vector Stores (v0.5.0 ðŸ†•)

- `NewChromaStore(baseURL)` - Create ChromaDB client
- `NewQdrantStore(baseURL)` - Create Qdrant client
- `CreateCollection(ctx, name, config)` - Create collection with config
- `Add(ctx, collection, documents)` - Add documents with auto-embedding
- `Search(ctx, request)` - Vector similarity search
- `SearchByText(ctx, request)` - Text-based semantic search
- `Delete(ctx, collection, ids)` - Delete documents by IDs
- `Count(ctx, collection)` - Get document count
- `Clear(ctx, collection)` - Remove all documents

## ðŸ—ï¸ Project Structure

```plaintext
go-deep-agent/
â”œâ”€â”€ agent/
â”‚   â”œâ”€â”€ builder.go              # Fluent Builder API
â”‚   â”œâ”€â”€ errors.go               # Custom error types
â”‚   â”œâ”€â”€ tools.go                # Tool calling support
â”‚   â”œâ”€â”€ *_test.go               # Comprehensive tests (76 tests)
â”‚   â””â”€â”€ README.md               # API documentation
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ builder_basic.go        # Basic examples
â”‚   â”œâ”€â”€ builder_streaming.go   # Streaming examples
â”‚   â”œâ”€â”€ builder_tools.go        # Tool calling examples
â”‚   â”œâ”€â”€ builder_json_schema.go # JSON Schema examples
â”‚   â”œâ”€â”€ builder_conversation.go # Memory management
â”‚   â”œâ”€â”€ builder_errors.go       # Error handling
â”‚   â”œâ”€â”€ ollama_example.go       # Ollama examples
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ main.go                     # Quick start demo
â”œâ”€â”€ README.md                   # You are here
â”œâ”€â”€ BUILDER_API.md              # Complete Builder API guide
â”œâ”€â”€ TODO.md                     # Development roadmap
â””â”€â”€ go.mod
```

## ðŸ“Š Quality Metrics

- âœ… **460+ Tests** passing across all features
- âœ… **65%+ Coverage** with comprehensive test cases
- âœ… **15 Example Files** with 70+ working examples
- âœ… **Production Libraries** (openai-go, govaluate, gonum)
- âœ… **Production Tested** with real OpenAI, Ollama, ChromaDB, Qdrant

## ðŸ› ï¸ Setup & Usage

### OpenAI Setup

```bash
# Set your API key
export OPENAI_API_KEY=your-api-key-here

# Run examples
go run main.go
```

### Ollama Setup

```bash
# Install Ollama
curl -fsSL https://ollama.com/install.sh | sh

# Pull a model
ollama pull qwen2.5:3b

# Pull embedding model (for vector RAG)
ollama pull nomic-embed-text

# Run Ollama server
ollama serve

# Run Ollama examples
go run examples/ollama_example.go
```

### Vector Database Setup (v0.5.0 ðŸ†•)

```bash
# ChromaDB (easiest for development)
docker run -p 8000:8000 chromadb/chroma

# OR Qdrant (production-ready)
docker run -p 6333:6333 qdrant/qdrant

# Run vector RAG examples
go run examples/vector_rag_example.go
go run examples/chroma_example.go
go run examples/qdrant_example.go
```

## ðŸƒ Running Examples

```bash
# Basic examples
go run examples/builder_basic.go

# Streaming examples
go run examples/builder_streaming.go

# Tool calling examples
go run examples/builder_tools.go

# JSON Schema examples (requires OPENAI_API_KEY)
go run examples/builder_json_schema.go

# Conversation management
go run examples/builder_conversation.go

# Error handling examples
go run examples/builder_errors.go

# Ollama examples (requires Ollama running)
go run examples/ollama_example.go

# Planning Layer examples (v0.7.1 ðŸ†•)
go run examples/planner_basic/main.go       # Basic sequential planning
go run examples/planner_parallel/main.go    # Parallel batch processing
go run examples/planner_adaptive/main.go    # Adaptive strategy switching

# Vector RAG examples (v0.5.0 ðŸ†•)
go run examples/embedding_example.go      # Embedding basics
go run examples/chroma_example.go         # ChromaDB integration
go run examples/qdrant_example.go         # Qdrant integration
go run examples/vector_rag_example.go     # Complete RAG workflow

# Quick demo with all features
go run main.go
```

## ðŸŽ¯ Design Philosophy

1. **Fluent API** - Method chaining for natural, readable code
2. **Smart Defaults** - Works out of the box, customize as needed
3. **Memory Management** - Automatic conversation history with FIFO truncation
4. **Error Recovery** - Intelligent retries with exponential backoff
5. **Type Safety** - Leverages Go's type system for safety
6. **Zero Surprises** - Predictable behavior, no hidden magic
7. **Production Ready** - Timeouts, retries, comprehensive error handling

## ðŸ§© Advanced Use Cases

### Multi-Round Tool Execution

```go
calculateTool := agent.NewTool("calculate", "Perform math calculations").
    AddParameter("expression", "string", "Math expression", true).
    WithHandler(func(args string) (string, error) {
        // ... calculation logic ...
        return result, nil
    })

response, err := agent.NewOpenAI("gpt-4o-mini", apiKey).
    WithTools(calculateTool).
    WithAutoExecute(true).
    WithMaxToolRounds(5).  // Allow multiple tool calls
    Ask(ctx, "Calculate (10 + 20) * 3, then add 50")
```

### Session Persistence

```go
builder := agent.NewOpenAI("gpt-4o-mini", apiKey).WithMemory()

// Have conversation
builder.Ask(ctx, "I'm learning Go")
builder.Ask(ctx, "Tell me about channels")

// Save session
session := builder.GetHistory()
saveToDatabase(session)

// Later: restore session
loadedSession := loadFromDatabase()
builder.SetHistory(loadedSession)
builder.Ask(ctx, "What were we talking about?")
```

### Production Error Handling

```go
func robustAsk(ctx context.Context, prompt string) (string, error) {
    builder := agent.NewOpenAI("gpt-4o-mini", apiKey).
        WithTimeout(30 * time.Second).
        WithRetry(3).
        WithExponentialBackoff()

    response, err := builder.Ask(ctx, prompt)
    if err != nil {
        if agent.IsTimeoutError(err) {
            return "", fmt.Errorf("request timed out after 30s")
        }
        if agent.IsRateLimitError(err) {
            time.Sleep(60 * time.Second) // Wait and retry
            return robustAsk(ctx, prompt)
        }
        return "", err
    }
    return response, nil
}
```

## ðŸ“‹ Requirements

- **Go 1.23.3** or higher
- **OpenAI API key** (for OpenAI provider)
- **Ollama** running locally (for Ollama provider)

## ðŸ†š Why Choose go-deep-agent?

**60-80% less code** than raw openai-go SDK with **10x better developer experience**.

| Feature | openai-go | go-deep-agent | Improvement |
|---------|-----------|---------------|-------------|
| Simple Chat | 26 lines | 14 lines | â¬‡ï¸ 46% |
| Streaming | 20+ lines | 5 lines | â¬‡ï¸ 75% |
| Memory | 28+ lines (manual) | 6 lines (auto) | â¬‡ï¸ 78% |
| Tool Calling | 50+ lines | 14 lines | â¬‡ï¸ 72% |
| Multimodal | 25+ lines | 5 lines | â¬‡ï¸ 80% |

**[ðŸ“– See detailed comparison with code examples â†’](docs/COMPARISON.md)**

### Key Advantages

- âœ… **Fluent API** - Method chaining reads like natural language
- âœ… **Modular Architecture** - Builder split into 10 focused files (61% reduction, v0.6.0 refactoring)
- âœ… **Automatic Features** - Memory, retry, error handling built-in
- âœ… **Production-Ready** - 470+ tests, 65.2% coverage, CI/CD, comprehensive benchmarks
- âœ… **Better DX** - IDE autocomplete, self-documenting code, clear file organization
- âœ… **All openai-go Features** - Plus high-level conveniences

## ðŸ¤ Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch
3. Add tests for new features
4. Ensure all tests pass: `go test ./...`
5. Submit a pull request

## ðŸ“„ License

MIT License - see [LICENSE](LICENSE) for details

## ï¿½ Security

**Overall Grade: B+ (82/100)** - Good security foundation with areas for improvement

### Current Security Features

âœ… **Input Validation** - 30+ Validate() methods across configs  
âœ… **Secret Redaction** - 6 regex patterns for API keys/tokens in debug logs  
âœ… **Path Traversal Prevention** - Blocks ".." in filesystem tool  
âœ… **Timeout Protection** - 30s default for HTTP/tools/requests  
âœ… **Structured Error Handling** - Security context tracking  

### Security Best Practices

```go
// âœ… Use environment variables for API keys
apiKey := os.Getenv("OPENAI_API_KEY")
if apiKey == "" {
    log.Fatal("OPENAI_API_KEY not set")
}

// âœ… Only enable safe tools
ai := tools.WithDefaults(agent.NewOpenAI("gpt-4o", apiKey))

// âœ… Set timeouts and retries
ai := ai.WithTimeout(30 * time.Second).WithMaxRetries(3)

// âœ… Disable debug in production
debug := os.Getenv("ENV") != "production"
ai := ai.WithDebug(debug)
```

### Security Documentation

- **[SECURITY_SUMMARY.md](docs/SECURITY_SUMMARY.md)** - ðŸ”’ Quick reference for security (v0.5.9 ðŸ†•)
- **[SECURITY_ANALYSIS.md](docs/SECURITY_ANALYSIS.md)** - ðŸ”’ Comprehensive security assessment (v0.5.9 ðŸ†•)

## ï¿½ðŸ“š Documentation

- **[README.md](README.md)** - Main documentation (you are here)
- **[MEMORY_SYSTEM_GUIDE.md](docs/MEMORY_SYSTEM_GUIDE.md)** - ðŸ§  Complete memory system guide: Memory vs Cache vs Vector Store (v0.7.10 ðŸ†•)
- **[COMPARISON.md](docs/COMPARISON.md)** - ðŸ†š Why go-deep-agent vs openai-go (with code examples)
- **[FEWSHOT_GUIDE.md](docs/FEWSHOT_GUIDE.md)** - ðŸŽ“ Few-Shot Learning complete guide (v0.6.5)
- **[PLANNING_GUIDE.md](docs/PLANNING_GUIDE.md)** - ðŸ§© Planning Layer concepts and patterns (v0.7.1 ðŸ†•)
- **[PLANNING_API.md](docs/PLANNING_API.md)** - ðŸ§© Planning Layer API reference (v0.7.1 ðŸ†•)
- **[PLANNING_PERFORMANCE.md](docs/PLANNING_PERFORMANCE.md)** - ðŸ§© Planning Layer benchmarks and tuning (v0.7.1 ðŸ†•)
- **[CHANGELOG.md](CHANGELOG.md)** - Version history and migration guides
- **[ERROR_HANDLING_BEST_PRACTICES.md](docs/ERROR_HANDLING_BEST_PRACTICES.md)** - ðŸ†• Complete error handling guide (v0.5.9)
- **[TROUBLESHOOTING.md](docs/TROUBLESHOOTING.md)** - ðŸ†• Common issues and solutions (v0.5.9)
- **[BUILDER_REFACTORING_PROPOSAL.md](docs/BUILDER_REFACTORING_PROPOSAL.md)** - ðŸ†• Builder refactoring details (v0.6.0)
- **[RAG_VECTOR_DATABASES.md](docs/RAG_VECTOR_DATABASES.md)** - Complete Vector RAG guide (v0.5.0)
- **[LOGGING_GUIDE.md](docs/LOGGING_GUIDE.md)** - Comprehensive logging & observability guide (v0.5.2)
- **[examples/](examples/)** - 75+ working examples across 25+ files
- **[agent/README.md](agent/README.md)** - Detailed API documentation
- **[TODO.md](TODO.md)** - Roadmap and implementation progress
- **[ROADMAP.md](ROADMAP.md)** - v0.5.0 Advanced RAG implementation plan

## ðŸ”— Links

- **GitHub**: [github.com/taipm/go-deep-agent](https://github.com/taipm/go-deep-agent)
- **openai-go**: [github.com/openai/openai-go](https://github.com/openai/openai-go) - Official OpenAI Go library
- **Ollama**: [ollama.com](https://ollama.com) - Run LLMs locally

---

<div align="center">

**Made with â¤ï¸ for the Go community**

â­ Star us on GitHub if you find this useful!

</div>